{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e46f9d-ba9a-4f0e-9fdb-fd62535d5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea52e92-8c9b-4d19-beb9-62df838cb0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "MODEL_NAME = \"llama3.2\"  \n",
    "VECTOR_DB_PATH = \"./chroma_db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789c957c-3ca6-48b3-a2da-3b8fe8d8d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- PASO 1: CARGAR DOCUMENTOS ---\n",
    "def cargar_documentos():\n",
    "    print(\" Cargando documentos...\")\n",
    "    docs = []\n",
    "    \n",
    "    # Cargar Filosof√≠a\n",
    "    if os.path.exists(\"data/teoria/filosofia_core.txt\"):\n",
    "        loader_teoria = TextLoader(\"data/teoria/filosofia_core.txt\", encoding=\"utf-8\")\n",
    "        docs_teoria = loader_teoria.load()\n",
    "        # A√±adimos metadatos para saber que esto es teor√≠a\n",
    "        for doc in docs_teoria:\n",
    "            doc.metadata[\"source_type\"] = \"teoria_filosofica\"\n",
    "        docs.extend(docs_teoria)\n",
    "    else:\n",
    "        print(\" ALERTA: No se encontr√≥ filosofia_core.txt\")\n",
    "\n",
    "    # Cargar Comentarios Gen Z\n",
    "    if os.path.exists(\"data/redes_sociales/comentarios_genz.txt\"):\n",
    "        loader_social = TextLoader(\"data/redes_sociales/comentarios_genz.txt\", encoding=\"utf-8\")\n",
    "        docs_social = loader_social.load()\n",
    "        # A√±adimos metadatos para saber que esto es evidencia emp√≠rica\n",
    "        for doc in docs_social:\n",
    "            doc.metadata[\"source_type\"] = \"redes_sociales\"\n",
    "        docs.extend(docs_social)\n",
    "    else:\n",
    "        print(\" ALERTA: No se encontr√≥ comentarios_genz.txt\")\n",
    "    \n",
    "    return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b30afc-4577-4100-bee4-299cd29e0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PASO 2: CREAR INDEX (EMBEDDINGS) ---\n",
    "def preparar_rag():\n",
    "    docs = cargar_documentos()\n",
    "    \n",
    "    # Dividir texto en fragmentos (chunks)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    print(f\" Documentos divididos en {len(splits)} fragmentos.\")\n",
    "\n",
    "    # Crear Embeddings (usamos un modelo ligero y r√°pido de HuggingFace local)\n",
    "    print(\" Generando base de datos vectorial (esto puede tardar unos segundos)...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Crear Vector Store (Persistente en disco para no rehacerlo siempre)\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits, \n",
    "        embedding=embeddings, \n",
    "        persist_directory=VECTOR_DB_PATH\n",
    "    )\n",
    "    print(\" Base de datos vectorial lista y guardada.\")\n",
    "    return vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8e640d-5a6c-4def-bd81-09bae147bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PASO 3: CONFIGURAR EL CEREBRO (LLAMA 3.2) ---\n",
    "def consultar_rag(pregunta, vectorstore):\n",
    "    # Definir el modelo\n",
    "    llm = ChatOllama(model=MODEL_NAME, temperature=0.3) # Temp baja para ser anal√≠tico\n",
    "    \n",
    "    # Definir el recuperador (Retriever)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5}) # Traer los 5 fragmentos m√°s relevantes\n",
    "\n",
    "    # Prompt del sistema (Instrucciones para Llama)\n",
    "    template = \"\"\"Eres un fil√≥sofo de datos experto en Byung-Chul Han, Foucault y Bauman.\n",
    "    Tu tarea es responder a la pregunta bas√°ndote SOLAMENTE en el contexto proporcionado.\n",
    "    \n",
    "    Instrucciones:\n",
    "    1. Analiza los comentarios de redes sociales en el contexto.\n",
    "    2. √önelos con los conceptos filos√≥ficos de la teor√≠a (pan√≥ptico, sociedad del cansancio, modernidad l√≠quida).\n",
    "    3. Si no encuentras la respuesta en el contexto, di \"No tengo suficientes datos para responder esto\".\n",
    "    4. Cita ejemplos concretos de los comentarios si los hay.\n",
    "\n",
    "    Contexto: {context}\n",
    "\n",
    "    Pregunta: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Crear la cadena (Chain)\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    print(f\"\\nü§î Analizando: '{pregunta}'...\")\n",
    "    print(\"-\" * 50)\n",
    "    resultado = rag_chain.invoke(pregunta)\n",
    "    return resultado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ea3d7d-6c21-46a0-afcf-36a60fd008fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando base de datos existente...\n",
      "\n",
      "ü§î Analizando: '¬øQu√© expresiones o t√©rminos utiliza la Gen Z para describir el vac√≠o existencial en redes sociales?'...\n",
      "--------------------------------------------------\n",
      "\n",
      "üìù RESPUESTA DE LLAMA 3.2:\n",
      "Bas√°ndome en los comentarios de redes sociales proporcionados, puedo identificar algunas expresiones y t√©rminos utilizados por la Gen Z para describir el vac√≠o existencial en redes sociales. A continuaci√≥n, te presento algunos ejemplos:\n",
      "\n",
      "1. \"Falta de dignidad\" - En el comentario n√∫mero 1, se menciona que las familias hacen ciudadanos d√©biles y carentes de dignidad para luchar por su libertad. Esto sugiere que la Gen Z percibe a s√≠ misma como d√©bil y sin dignidad en comparaci√≥n con sus antepasados.\n",
      "2. \"Situaciones dif√≠ciles y peligrosas\" - En el mismo comentario, se menciona que los que pelean por un mundo libre de sistemas putrefactos son perseguidos y se ver√°n envueltos en situaciones dif√≠ciles y peligrosas. Esto sugiere que la Gen Z percibe a s√≠ misma como vulnerable y expuesta a riesgos.\n",
      "3. \"Cansancio existencial\" - En el comentario n√∫mero 4, se menciona que algunos se criaron mediante la culpa debido a la gran influencia arrastrada por parte del cristianismo. Esto sugiere que la Gen Z percibe a s√≠ misma como cansada y agotada emocionalmente.\n",
      "4. \"Superficialidad emocional\" - En el comentario n√∫mero 5, se menciona que las pantallas redefinen la intimidad y el v√≠nculo humano, lo que puede generar una superficialidad emocional en las relaciones.\n",
      "\n",
      "En cuanto a los t√©rminos espec√≠ficos utilizados por Jean Baudrillard para describir la realidad hiperreal y la simulacros, no se mencionan expl√≠citamente en los comentarios. Sin embargo, el comentario n√∫mero 3 menciona que \"la lentitud se percibe como fracaso\", lo que puede estar relacionado con la idea de que la realidad hiperreal es tan intensa que nos hace perder de vista la verdadera realidad.\n",
      "\n",
      "En cuanto a las ideas de Paul Virilio y Hartmut Rosa sobre la aceleraci√≥n social, no se mencionan expl√≠citamente en los comentarios. Sin embargo, el comentario n√∫mero 4 menciona que \"la lentitud se percibe como fracaso\", lo que puede estar relacionado con la idea de que la sociedad est√° tan acelerada que nos hace perder de vista la importancia de la lentitud y la reflexi√≥n.\n",
      "\n",
      "En resumen, las expresiones y t√©rminos utilizados por la Gen Z para describir el vac√≠o existencial en redes sociales incluyen:\n",
      "\n",
      "* \"Falta de dignidad\"\n",
      "* \"Situaciones dif√≠ciles y peligrosas\"\n",
      "* \"Cansancio existencial\"\n",
      "* \"Superficialidad emocional\"\n",
      "\n",
      "Y, aunque no se mencionan expl√≠citamente los t√©rminos de Baudrillard y Virilio/Rosa, se pueden relacionar con las ideas sobre la realidad hiperreal y la simulacros, as√≠ como la aceleraci√≥n social.\n"
     ]
    }
   ],
   "source": [
    "# 1. Preparar o cargar la BD\n",
    "if os.path.exists(VECTOR_DB_PATH):\n",
    "    print(\"üìÇ Cargando base de datos existente...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = Chroma(persist_directory=VECTOR_DB_PATH, embedding_function=embeddings)\n",
    "else:\n",
    "    vectorstore = preparar_rag()\n",
    "\n",
    "# 2. Prueba r√°pida\n",
    "pregunta_prueba = \"¬øQu√© expresiones o t√©rminos utiliza la Gen Z para describir el vac√≠o existencial en redes sociales?\"\n",
    "respuesta = consultar_rag(pregunta_prueba, vectorstore)\n",
    "\n",
    "print(\"\\nüìù RESPUESTA DE LLAMA 3.2:\")\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe73f00-171f-40fc-ab8b-193e98442a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
